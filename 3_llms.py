# -*- coding: utf-8 -*-
"""3_llms.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G8JOhZTXFlO_1cDPh9urw8aBCbFqt5FZ

# Create Dataset
"""

import pandas as pd
import numpy as np
import torch
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.utils import compute_class_weight, resample
from sklearn.metrics import (
    accuracy_score, f1_score, precision_score, recall_score,
    confusion_matrix, roc_curve, auc
)

from imblearn.over_sampling import SMOTE

from datasets import Dataset
from transformers import (
    AutoTokenizer, DistilBertForSequenceClassification,
    AutoModelForSequenceClassification, Trainer, TrainingArguments,
    DataCollatorWithPadding
)
from torch.nn import CrossEntropyLoss
from transformers import EarlyStoppingCallback

from transformers import TrainerCallback
import psutil
import subprocess
import csv
import os
from datetime import datetime

df = pd.read_csv('./drive/MyDrive/WA_Fn-UseC_-Telco-Customer-Churn.csv')

df.drop(columns=['customerID'],inplace=True)

df['Churn'] = df['Churn'].map({'Yes':1,'No':0})

def convert_to_text(df):
  rows = []
  for index,row in df.iterrows():
    st = "User's gender is "+str(row['gender']) + ", "
    st += (lambda row: "user is senior citizen, " if row['SeniorCitizen'] else "user is not senior citizen, ")(row)
    st += (lambda row: "user have no partner, " if row['Partner'] == "No" else "user have partner, ")(row)
    st += (lambda row: "user have dependents, " if row['Dependents'] == "No" else "user dont have dependents, ")(row)
    st += "user's tenure is "+str(row['tenure']) + ", "
    st += (lambda row: "user have no phone service, " if row['PhoneService'] == "No" else "user have phone service, ")(row)

    if row['InternetService'] == "Fiber optic":
      st += "user have fiber optic internet service, "
    elif row['InternetService'] == "DSL":
      st += "user have DSL internet service, "

    if row['MultipleLines'] == "No":
      st += "user dont have multiple lines, "
    elif row['MultipleLines'] == "No phone service":
      st += "user dont have phone service, "
    else:
      st += "user have multiple lines, "

    if row['OnlineSecurity'] == "No internet service":
      st += "user dont have internet service, "
    elif row['OnlineSecurity'] == "No":
      st += "user dont have online security, "
    else:
      st += "user have online security, "

    st += (lambda row: "user dont have online backup, " if row['OnlineBackup'] == "No" else "user have online backup, ")(row)
    st += (lambda row: "user dont have device protection, " if row['DeviceProtection'] == "No" else "user have device protection, ")(row)
    st += (lambda row: "user dont have tech support, " if row['TechSupport'] == "No" else "user have tech support, ")(row)
    st += (lambda row: "user dont have streaming tv, " if row['StreamingTV'] == "No" else "user have streaming tv, ")(row)
    st += (lambda row: "user dont have streaming movies, " if row['StreamingMovies'] == "No" else "user have streaming movies, ")(row)
    st += "user's contract is "+str(row['Contract']) + ", "
    st += (lambda row: "user dont have paperless billing, " if row['PaperlessBilling'] == "No" else "user have paperless billing, ")(row)
    st += "user's payment method is "+str(row['PaymentMethod']) + ", "
    st += "user's monthly charge is "+str(row['MonthlyCharges']) + ", "
    st += "user's total charges is "+str(row['TotalCharges']) + ", "
    rows.append({'text':st, 'label':row['Churn']})
  new_df = pd.DataFrame(rows)
  return new_df

train_df_org, test_df_org = train_test_split(df, test_size=0.2, random_state=42, stratify = df['Churn'])

train_df = convert_to_text(train_df_org)
test_df = convert_to_text(test_df_org)

train_df.to_csv('./drive/MyDrive/train_df.csv',index=False)
test_df.to_csv('./drive/MyDrive/test_df.csv',index=False)

"""# Use The dataset with BERT"""

train_df = pd.read_csv('./drive/MyDrive/train_df.csv')
test_df = pd.read_csv('./drive/MyDrive/test_df.csv')

class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_df['label']), y=train_df['label'])
weights = torch.tensor(class_weights, dtype=torch.float)

tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")

train_dataset = Dataset.from_pandas(train_df)
test_dataset = Dataset.from_pandas(test_df)

def tokenize_data(examples):
    return tokenizer(examples["text"], truncation=True)

tokenized_train = train_dataset.map(tokenize_data, batched=True)
tokenized_test = test_dataset.map(tokenize_data, batched=True)

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    preds = logits.argmax(axis=-1)
    return {
        'accuracy': accuracy_score(labels, preds),
        'f1': f1_score(labels, preds)
    }

class WeightedLossTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):
        labels = inputs.get("labels")
        outputs = model(**inputs)
        logits = outputs.get("logits")
        loss_fct = CrossEntropyLoss(weight=weights.to(model.device))
        loss = loss_fct(logits, labels)
        return (loss, outputs) if return_outputs else loss

class HardwareMonitorCallback(TrainerCallback):
    def __init__(self, log_path="hardware_log.csv"):
        self.log_path = log_path
        with open(self.log_path, mode='w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                "timestamp", "cpu_percent", "ram_used_MB", "ram_total_MB",
                "gpu_util_percent", "gpu_mem_used_MB", "gpu_mem_total_MB"
            ])

    def get_gpu_usage(self):
        try:
            result = subprocess.check_output(
                ["nvidia-smi", "--query-gpu=utilization.gpu,memory.used,memory.total",
                 "--format=csv,noheader,nounits"], encoding='utf-8'
            )
            gpu_util, mem_used, mem_total = result.strip().split(", ")
            return int(gpu_util), int(mem_used), int(mem_total)
        except Exception:
            return 0, 0, 0

    def on_step_end(self, args, state, control, **kwargs):
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        cpu_percent = psutil.cpu_percent()
        mem = psutil.virtual_memory()
        ram_used = mem.used / (1024 * 1024)
        ram_total = mem.total / (1024 * 1024)
        gpu_util, gpu_mem_used, gpu_mem_total = self.get_gpu_usage()

        with open(self.log_path, mode='a', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                timestamp, cpu_percent, ram_used, ram_total,
                gpu_util, gpu_mem_used, gpu_mem_total
            ])

model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=2)

data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

training_args = TrainingArguments(
    output_dir="./results",
    auto_find_batch_size=True,
    learning_rate=6e-5,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=32,
    num_train_epochs=20,
    eval_strategy="epoch",
    save_strategy="epoch",
    save_total_limit=2,
    load_best_model_at_end=True,
    metric_for_best_model="f1",
    logging_steps=100,
    report_to="none",
)

trainer = WeightedLossTrainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_train,
    eval_dataset=tokenized_test,
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=4),HardwareMonitorCallback(log_path="hardware_log.csv")]
)

trainer.train()

trainer.evaluate()

trainer.save_model('drive/MyDrive/distilbert_model0')

predictions = trainer.predict(tokenized_test)
predicted_labels = np.argmax(predictions.predictions, axis=1)
true_labels = tokenized_test["label"]
results_df = pd.DataFrame({'True_Label': true_labels, 'Predicted_Label': predicted_labels})

"""# Model Analysis"""

cm = confusion_matrix(results_df['True_Label'], results_df['Predicted_Label'])

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False,
            xticklabels=['Predicted No Churn', 'Predicted Churn'],
            yticklabels=['Actual No Churn', 'Actual Churn'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

from scipy.special import softmax
predicted_probs = predictions.predictions[:, 1]
fpr, tpr, thresholds = roc_curve(true_labels, predicted_probs)

roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

"""# Hardware Usage Analysis"""

hardware_logs = pd.read_csv('hardware_log.csv')

hardware_logs.head()

# @title CPU Usage Over Time

plt.figure
plt.plot(hardware_logs['cpu_percent'], label='CPU Usage')
plt.xlabel('Time')
plt.ylabel('CPU Usage (%)')
plt.title('CPU Usage Over Time')
plt.legend()
plt.show()

# @title Memory Usage Over Time in (MB)

plt.figure
plt.plot(hardware_logs['ram_used_MB'])
plt.xlabel('Time')
plt.ylabel('Memory Usage (MB)')
plt.title('Memory Usage Over Time')
plt.legend()
plt.show()

# @title GPU Memory Usage Over Time
plt.figure
plt.plot(hardware_logs['gpu_mem_used_MB'])
plt.xlabel('Time')
plt.ylabel('GPU Memory Usage (MB)')
plt.title('GPU Memory Usage Over Time')
plt.legend()
plt.show()

# @title GPU Memory Usage in (%) Over Time

plt.figure
plt.plot(hardware_logs['gpu_util_percent'])
plt.xlabel('Time')
plt.ylabel('GPU Memory Usage (%)')
plt.title('GPU Memory Usage in (%) Over Time')
plt.legend()
plt.show()

# @title RAM Memory Usage (MB) vs GPU Usage (%)

from matplotlib import pyplot as plt
hardware_logs.plot(kind='scatter', x='ram_used_MB', y='gpu_util_percent', s=32, alpha=.8)
plt.xlabel('RAM Memory Usage (MB)')
plt.ylabel('GPU Usage (%)')
plt.title('RAM Memory Usage (MB) vs GPU Usage (%)')
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title RAM Memory Usage (MB) vs CPU Usage (%)

from matplotlib import pyplot as plt
hardware_logs.plot(kind='scatter', x='ram_used_MB', y='cpu_percent', s=32, alpha=.8)
plt.xlabel('RAM Memory Usage (MB)')
plt.ylabel('CPU Usage (%)')
plt.title('RAM Memory Usage (MB) vs CPU Usage (%)')
plt.gca().spines[['top', 'right',]].set_visible(False)

"""# Use the model"""

model = AutoModelForSequenceClassification.from_pretrained("drive/MyDrive/distilbert_model0/", num_labels=2)

def predict(t):
    tokenized_input = tokenizer(t, return_tensors="pt")

    device = model.device
    tokenized_input = {k: v.to(device) for k, v in tokenized_input.items()}

    with torch.no_grad():
        outputs = model(**tokenized_input)
        logits = outputs.logits
        probs = torch.softmax(logits, dim=1)

    predicted_class = torch.argmax(probs).item()
    return probs